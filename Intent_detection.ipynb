{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Reference\n",
        "1. The codes for DeepSORT was adapted from the GitHub repo: https://github.com/nwojke/deep_sort\n",
        "\n",
        "2. The codes for Skeleton FittingTF-PoseEstimator was adapted from the GitHub repo: https://github.com/ildoonet/tf-pose-estimation\n",
        "\n",
        "3. The codes for ST-DenseNet was adapted from the GitHub repo: https://github.com/GalDude33/DenseNetFCN-3D\n",
        "\n",
        "4. The codes for YOLOv3 was adapted from the GitHub repo: https://github.com/zzh8829/yolov3-tf2"
      ],
      "metadata": {
        "id": "6FnekoRUabfE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GQb7BBdXabJ"
      },
      "source": [
        "## 1. Run this to install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7n4Q7G2Ui2i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "60440b9a-5d87-4244-ddfc-450347fbda4c"
      },
      "source": [
        "%cd Volvo-DataX/tf-pose-estimation\n",
        "! pip3 install -r requirements.txt\n",
        "%cd tf_pose/pafprocess\n",
        "! sudo apt install swig\n",
        "!swig -python -c++ pafprocess.i && python3 setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Volvo-DataX/tf-pose-estimation\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ppwwyyxx/tensorpack.git (from -r requirements.txt (line 13))\n",
            "  Cloning https://github.com/ppwwyyxx/tensorpack.git to /tmp/pip-req-build-g31p48rf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ppwwyyxx/tensorpack.git /tmp/pip-req-build-g31p48rf\n",
            "  Resolved https://github.com/ppwwyyxx/tensorpack.git to commit a9a2660d9ebe8fe4f32693b59f1e003687716d81\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.56.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (5.9.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.27.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.10.1)\n",
            "Collecting slidingwindow\n",
            "  Downloading slidingwindow-0.0.14-py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (4.39.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (23.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.22.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->-r requirements.txt (line 5)) (0.39.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 8)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 8)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 8)) (2.0.12)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 9)) (2.25.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 9)) (3.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from tensorpack==0.11->-r requirements.txt (line 13)) (0.8.10)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from tensorpack==0.11->-r requirements.txt (line 13)) (1.0.5)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.10/dist-packages (from tensorpack==0.11->-r requirements.txt (line 13)) (23.2.1)\n",
            "Building wheels for collected packages: fire, tensorpack\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=d21d49fa65c01319cd7d5ee3b205d4f15a06c128f4ca9f5d62b63ac66c0205ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for tensorpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorpack: filename=tensorpack-0.11-py2.py3-none-any.whl size=296939 sha256=993199d818bc6c2f0f81b58d232c53fd117d019ef3aef1936e9fe94bec46fb73\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0nfnm6za/wheels/5c/3c/c2/67bbb4e71311106e703ad7d0800d112f81bf8b026a3f359430\n",
            "Successfully built fire tensorpack\n",
            "Installing collected packages: argparse, slidingwindow, msgpack-numpy, fire, dill, tensorpack\n",
            "Successfully installed argparse-1.4.0 dill-0.3.6 fire-0.5.0 msgpack-numpy-0.4.8 slidingwindow-0.0.14 tensorpack-0.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Volvo-DataX/tf-pose-estimation/tf_pose/pafprocess\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 1,086 kB of archives.\n",
            "After this operation, 5,413 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 swig4.0 amd64 4.0.1-5build1 [1,081 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 swig all 4.0.1-5build1 [5,528 B]\n",
            "Fetched 1,086 kB in 1s (1,302 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.1-5build1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.1-5build1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.1-5build1_all.deb ...\n",
            "Unpacking swig (4.0.1-5build1) ...\n",
            "Setting up swig4.0 (4.0.1-5build1) ...\n",
            "Setting up swig (4.0.1-5build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "/content/Volvo-DataX/tf-pose-estimation/tf_pose/pafprocess/setup.py:1: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
            "  from distutils.core import setup, Extension\n",
            "running build_ext\n",
            "building '_pafprocess' extension\n",
            "swigging pafprocess.i to pafprocess_wrap.cpp\n",
            "swig -python -c++ -o pafprocess_wrap.cpp pafprocess.i\n",
            "creating build/temp.linux-x86_64-3.10\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I. -I/usr/include/python3.10 -c pafprocess.cpp -o build/temp.linux-x86_64-3.10/pafprocess.o\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I. -I/usr/include/python3.10 -c pafprocess_wrap.cpp -o build/temp.linux-x86_64-3.10/pafprocess_wrap.o\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC build/temp.linux-x86_64-3.10/pafprocess.o build/temp.linux-x86_64-3.10/pafprocess_wrap.o -o /content/Volvo-DataX/tf-pose-estimation/tf_pose/pafprocess/_pafprocess.cpython-310-x86_64-linux-gnu.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCqcNrkJ1GcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c41804-ccdf-4b08-de93-8e62be2874ec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfFLtD0fWj96"
      },
      "source": [
        "###5. Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU6qWoWr1QpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7011e7fb-5794-4015-aa86-5444eed0f515"
      },
      "source": [
        "# run this\n",
        "%cd /content/Volvo-DataX\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import glob\n",
        "\n",
        "import sys #Run this\n",
        "from absl import app, logging, flags\n",
        "from absl.flags import FLAGS\n",
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from yolov3_tf2.models import (\n",
        "    YoloV3, YoloV3Tiny\n",
        ")\n",
        "from yolov3_tf2.dataset import transform_images, load_tfrecord_dataset\n",
        "from yolov3_tf2.utils import draw_outputs\n",
        "\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "flags.DEFINE_string('classes', 'data/coco.names', 'path to classes file')\n",
        "flags.DEFINE_string('weights', '/content/drive/My Drive/datax_volvo_additional_files/yolov3_train_5.tf','path to weights file')\n",
        "flags.DEFINE_boolean('tiny', False, 'yolov3 or yolov3-tiny')\n",
        "flags.DEFINE_integer('size', 416, 'resize images to')\n",
        "flags.DEFINE_string('tfrecord', None, 'tfrecord instead of image')\n",
        "flags.DEFINE_integer('num_classes', 1, 'number of classes in the model')\n",
        "flags.DEFINE_string('video', 'data/JAAD_test_video_0339.mp4','path to video file or number for webcam)')\n",
        "flags.DEFINE_string('output','Result_model_D.mp4', 'path to output video')\n",
        "flags.DEFINE_string('output_format', 'mp4v', 'codec used in VideoWriter when saving video to file')\n",
        "\n",
        "app._run_init(['yolov3'], app.parse_flags_with_usage)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Volvo-DataX\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yolov3']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsuZt3UXTH_x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c2537c-66fe-4e4d-9e9e-b3659e88200b"
      },
      "source": [
        "%cd /content/Volvo-DataX/deep_sort\n",
        "from ds_tools.generate_detections import create_box_encoder\n",
        "from ds_application_util import preprocessing\n",
        "from ds_deep_sort import nn_matching\n",
        "from ds_deep_sort.detection import Detection\n",
        "from ds_deep_sort.tracker import Tracker\n",
        "\n",
        "%cd /content/Volvo-DataX/tf-pose-estimation\n",
        "from tf_pose.estimator import TfPoseEstimator\n",
        "from tf_pose.networks import get_graph_path, model_wh\n",
        "from tf_pose.estimator import Human\n",
        "model = TfPoseEstimator(get_graph_path('egen_jaad_1_5'), target_size=(100, 100))\n",
        "\n",
        "%cd /content/Volvo-DataX\n",
        "\n",
        "nms_max_overlap = 1.0\n",
        "max_cosine_distance = 0.2\n",
        "nn_budget = None\n",
        "encoder = create_box_encoder('mars-small128.pb', batch_size=32)\n",
        "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
        "tracker = Tracker(metric)\n",
        "\n",
        "with open('densenet_model.json', 'r') as json_file:\n",
        "    json_savedModel= json_file.read()\n",
        "\n",
        "model_j = tf.keras.models.model_from_json(json_savedModel)\n",
        "model_j.load_weights('densenet_2.hdf5')\n",
        "\n",
        "def pred_func(X_test):\n",
        "  predictions = model_j.predict(X_test[0:1], verbose=0)\n",
        "  Y = np.argmax(predictions[0], axis=0)\n",
        "\n",
        "  return Y\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0504 06:51:47.193216 140519420950336 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Volvo-DataX/deep_sort\n",
            "/content/Volvo-DataX/tf-pose-estimation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils/linear_assignment_.py:18: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n",
            "[2023-05-04 06:51:47,796] [TfPoseEstimator] [INFO] loading graph from /content/drive/My Drive/datax_volvo_additional_files/graph_opt.pb(default size=100x100)\n",
            "I0504 06:51:47.796014 140519420950336 estimator.py:320] loading graph from /content/drive/My Drive/datax_volvo_additional_files/graph_opt.pb(default size=100x100)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TfPoseEstimator/preprocess_divide/y\n",
            "TfPoseEstimator/preprocess_subtract/y\n",
            "TfPoseEstimator/concat_stage2/axis\n",
            "TfPoseEstimator/concat_stage3/axis\n",
            "TfPoseEstimator/concat_stage4/axis\n",
            "TfPoseEstimator/concat_stage5/axis\n",
            "TfPoseEstimator/concat_stage6/axis\n",
            "TfPoseEstimator/Openpose/concat_stage7/axis\n",
            "TfPoseEstimator/Mconv1_stage2_L1/biases/read/_0__cf__0\n",
            "TfPoseEstimator/Mconv1_stage2_L1/weights/read/_1__cf__1\n",
            "TfPoseEstimator/Mconv1_stage2_L2/biases/read/_2__cf__2\n",
            "TfPoseEstimator/Mconv1_stage2_L2/weights/read/_3__cf__3\n",
            "TfPoseEstimator/Mconv1_stage3_L1/biases/read/_4__cf__4\n",
            "TfPoseEstimator/Mconv1_stage3_L1/weights/read/_5__cf__5\n",
            "TfPoseEstimator/Mconv1_stage3_L2/biases/read/_6__cf__6\n",
            "TfPoseEstimator/Mconv1_stage3_L2/weights/read/_7__cf__7\n",
            "TfPoseEstimator/Mconv1_stage4_L1/biases/read/_8__cf__8\n",
            "TfPoseEstimator/Mconv1_stage4_L1/weights/read/_9__cf__9\n",
            "TfPoseEstimator/Mconv1_stage4_L2/biases/read/_10__cf__10\n",
            "TfPoseEstimator/Mconv1_stage4_L2/weights/read/_11__cf__11\n",
            "TfPoseEstimator/Mconv1_stage5_L1/biases/read/_12__cf__12\n",
            "TfPoseEstimator/Mconv1_stage5_L1/weights/read/_13__cf__13\n",
            "TfPoseEstimator/Mconv1_stage5_L2/biases/read/_14__cf__14\n",
            "TfPoseEstimator/Mconv1_stage5_L2/weights/read/_15__cf__15\n",
            "TfPoseEstimator/Mconv1_stage6_L1/biases/read/_16__cf__16\n",
            "TfPoseEstimator/Mconv1_stage6_L1/weights/read/_17__cf__17\n",
            "TfPoseEstimator/Mconv1_stage6_L2/biases/read/_18__cf__18\n",
            "TfPoseEstimator/Mconv1_stage6_L2/weights/read/_19__cf__19\n",
            "TfPoseEstimator/Mconv2_stage2_L1/biases/read/_20__cf__20\n",
            "TfPoseEstimator/Mconv2_stage2_L1/weights/read/_21__cf__21\n",
            "TfPoseEstimator/Mconv2_stage2_L2/biases/read/_22__cf__22\n",
            "TfPoseEstimator/Mconv2_stage2_L2/weights/read/_23__cf__23\n",
            "TfPoseEstimator/Mconv2_stage3_L1/biases/read/_24__cf__24\n",
            "TfPoseEstimator/Mconv2_stage3_L1/weights/read/_25__cf__25\n",
            "TfPoseEstimator/Mconv2_stage3_L2/biases/read/_26__cf__26\n",
            "TfPoseEstimator/Mconv2_stage3_L2/weights/read/_27__cf__27\n",
            "TfPoseEstimator/Mconv2_stage4_L1/biases/read/_28__cf__28\n",
            "TfPoseEstimator/Mconv2_stage4_L1/weights/read/_29__cf__29\n",
            "TfPoseEstimator/Mconv2_stage4_L2/biases/read/_30__cf__30\n",
            "TfPoseEstimator/Mconv2_stage4_L2/weights/read/_31__cf__31\n",
            "TfPoseEstimator/Mconv2_stage5_L1/biases/read/_32__cf__32\n",
            "TfPoseEstimator/Mconv2_stage5_L1/weights/read/_33__cf__33\n",
            "TfPoseEstimator/Mconv2_stage5_L2/biases/read/_34__cf__34\n",
            "TfPoseEstimator/Mconv2_stage5_L2/weights/read/_35__cf__35\n",
            "TfPoseEstimator/Mconv2_stage6_L1/biases/read/_36__cf__36\n",
            "TfPoseEstimator/Mconv2_stage6_L1/weights/read/_37__cf__37\n",
            "TfPoseEstimator/Mconv2_stage6_L2/biases/read/_38__cf__38\n",
            "TfPoseEstimator/Mconv2_stage6_L2/weights/read/_39__cf__39\n",
            "TfPoseEstimator/Mconv3_stage2_L1/biases/read/_40__cf__40\n",
            "TfPoseEstimator/Mconv3_stage2_L1/weights/read/_41__cf__41\n",
            "TfPoseEstimator/Mconv3_stage2_L2/biases/read/_42__cf__42\n",
            "TfPoseEstimator/Mconv3_stage2_L2/weights/read/_43__cf__43\n",
            "TfPoseEstimator/Mconv3_stage3_L1/biases/read/_44__cf__44\n",
            "TfPoseEstimator/Mconv3_stage3_L1/weights/read/_45__cf__45\n",
            "TfPoseEstimator/Mconv3_stage3_L2/biases/read/_46__cf__46\n",
            "TfPoseEstimator/Mconv3_stage3_L2/weights/read/_47__cf__47\n",
            "TfPoseEstimator/Mconv3_stage4_L1/biases/read/_48__cf__48\n",
            "TfPoseEstimator/Mconv3_stage4_L1/weights/read/_49__cf__49\n",
            "TfPoseEstimator/Mconv3_stage4_L2/biases/read/_50__cf__50\n",
            "TfPoseEstimator/Mconv3_stage4_L2/weights/read/_51__cf__51\n",
            "TfPoseEstimator/Mconv3_stage5_L1/biases/read/_52__cf__52\n",
            "TfPoseEstimator/Mconv3_stage5_L1/weights/read/_53__cf__53\n",
            "TfPoseEstimator/Mconv3_stage5_L2/biases/read/_54__cf__54\n",
            "TfPoseEstimator/Mconv3_stage5_L2/weights/read/_55__cf__55\n",
            "TfPoseEstimator/Mconv3_stage6_L1/biases/read/_56__cf__56\n",
            "TfPoseEstimator/Mconv3_stage6_L1/weights/read/_57__cf__57\n",
            "TfPoseEstimator/Mconv3_stage6_L2/biases/read/_58__cf__58\n",
            "TfPoseEstimator/Mconv3_stage6_L2/weights/read/_59__cf__59\n",
            "TfPoseEstimator/Mconv4_stage2_L1/biases/read/_60__cf__60\n",
            "TfPoseEstimator/Mconv4_stage2_L1/weights/read/_61__cf__61\n",
            "TfPoseEstimator/Mconv4_stage2_L2/biases/read/_62__cf__62\n",
            "TfPoseEstimator/Mconv4_stage2_L2/weights/read/_63__cf__63\n",
            "TfPoseEstimator/Mconv4_stage3_L1/biases/read/_64__cf__64\n",
            "TfPoseEstimator/Mconv4_stage3_L1/weights/read/_65__cf__65\n",
            "TfPoseEstimator/Mconv4_stage3_L2/biases/read/_66__cf__66\n",
            "TfPoseEstimator/Mconv4_stage3_L2/weights/read/_67__cf__67\n",
            "TfPoseEstimator/Mconv4_stage4_L1/biases/read/_68__cf__68\n",
            "TfPoseEstimator/Mconv4_stage4_L1/weights/read/_69__cf__69\n",
            "TfPoseEstimator/Mconv4_stage4_L2/biases/read/_70__cf__70\n",
            "TfPoseEstimator/Mconv4_stage4_L2/weights/read/_71__cf__71\n",
            "TfPoseEstimator/Mconv4_stage5_L1/biases/read/_72__cf__72\n",
            "TfPoseEstimator/Mconv4_stage5_L1/weights/read/_73__cf__73\n",
            "TfPoseEstimator/Mconv4_stage5_L2/biases/read/_74__cf__74\n",
            "TfPoseEstimator/Mconv4_stage5_L2/weights/read/_75__cf__75\n",
            "TfPoseEstimator/Mconv4_stage6_L1/biases/read/_76__cf__76\n",
            "TfPoseEstimator/Mconv4_stage6_L1/weights/read/_77__cf__77\n",
            "TfPoseEstimator/Mconv4_stage6_L2/biases/read/_78__cf__78\n",
            "TfPoseEstimator/Mconv4_stage6_L2/weights/read/_79__cf__79\n",
            "TfPoseEstimator/Mconv5_stage2_L1/biases/read/_80__cf__80\n",
            "TfPoseEstimator/Mconv5_stage2_L1/weights/read/_81__cf__81\n",
            "TfPoseEstimator/Mconv5_stage2_L2/biases/read/_82__cf__82\n",
            "TfPoseEstimator/Mconv5_stage2_L2/weights/read/_83__cf__83\n",
            "TfPoseEstimator/Mconv5_stage3_L1/biases/read/_84__cf__84\n",
            "TfPoseEstimator/Mconv5_stage3_L1/weights/read/_85__cf__85\n",
            "TfPoseEstimator/Mconv5_stage3_L2/biases/read/_86__cf__86\n",
            "TfPoseEstimator/Mconv5_stage3_L2/weights/read/_87__cf__87\n",
            "TfPoseEstimator/Mconv5_stage4_L1/biases/read/_88__cf__88\n",
            "TfPoseEstimator/Mconv5_stage4_L1/weights/read/_89__cf__89\n",
            "TfPoseEstimator/Mconv5_stage4_L2/biases/read/_90__cf__90\n",
            "TfPoseEstimator/Mconv5_stage4_L2/weights/read/_91__cf__91\n",
            "TfPoseEstimator/Mconv5_stage5_L1/biases/read/_92__cf__92\n",
            "TfPoseEstimator/Mconv5_stage5_L1/weights/read/_93__cf__93\n",
            "TfPoseEstimator/Mconv5_stage5_L2/biases/read/_94__cf__94\n",
            "TfPoseEstimator/Mconv5_stage5_L2/weights/read/_95__cf__95\n",
            "TfPoseEstimator/Mconv5_stage6_L1/biases/read/_96__cf__96\n",
            "TfPoseEstimator/Mconv5_stage6_L1/weights/read/_97__cf__97\n",
            "TfPoseEstimator/Mconv5_stage6_L2/biases/read/_98__cf__98\n",
            "TfPoseEstimator/Mconv5_stage6_L2/weights/read/_99__cf__99\n",
            "TfPoseEstimator/Mconv6_stage2_L1/biases/read/_100__cf__100\n",
            "TfPoseEstimator/Mconv6_stage2_L1/weights/read/_101__cf__101\n",
            "TfPoseEstimator/Mconv6_stage2_L2/biases/read/_102__cf__102\n",
            "TfPoseEstimator/Mconv6_stage2_L2/weights/read/_103__cf__103\n",
            "TfPoseEstimator/Mconv6_stage3_L1/biases/read/_104__cf__104\n",
            "TfPoseEstimator/Mconv6_stage3_L1/weights/read/_105__cf__105\n",
            "TfPoseEstimator/Mconv6_stage3_L2/biases/read/_106__cf__106\n",
            "TfPoseEstimator/Mconv6_stage3_L2/weights/read/_107__cf__107\n",
            "TfPoseEstimator/Mconv6_stage4_L1/biases/read/_108__cf__108\n",
            "TfPoseEstimator/Mconv6_stage4_L1/weights/read/_109__cf__109\n",
            "TfPoseEstimator/Mconv6_stage4_L2/biases/read/_110__cf__110\n",
            "TfPoseEstimator/Mconv6_stage4_L2/weights/read/_111__cf__111\n",
            "TfPoseEstimator/Mconv6_stage5_L1/biases/read/_112__cf__112\n",
            "TfPoseEstimator/Mconv6_stage5_L1/weights/read/_113__cf__113\n",
            "TfPoseEstimator/Mconv6_stage5_L2/biases/read/_114__cf__114\n",
            "TfPoseEstimator/Mconv6_stage5_L2/weights/read/_115__cf__115\n",
            "TfPoseEstimator/Mconv6_stage6_L1/biases/read/_116__cf__116\n",
            "TfPoseEstimator/Mconv6_stage6_L1/weights/read/_117__cf__117\n",
            "TfPoseEstimator/Mconv6_stage6_L2/biases/read/_118__cf__118\n",
            "TfPoseEstimator/Mconv6_stage6_L2/weights/read/_119__cf__119\n",
            "TfPoseEstimator/Mconv7_stage2_L1/biases/read/_120__cf__120\n",
            "TfPoseEstimator/Mconv7_stage2_L1/weights/read/_121__cf__121\n",
            "TfPoseEstimator/Mconv7_stage2_L2/biases/read/_122__cf__122\n",
            "TfPoseEstimator/Mconv7_stage2_L2/weights/read/_123__cf__123\n",
            "TfPoseEstimator/Mconv7_stage3_L1/biases/read/_124__cf__124\n",
            "TfPoseEstimator/Mconv7_stage3_L1/weights/read/_125__cf__125\n",
            "TfPoseEstimator/Mconv7_stage3_L2/biases/read/_126__cf__126\n",
            "TfPoseEstimator/Mconv7_stage3_L2/weights/read/_127__cf__127\n",
            "TfPoseEstimator/Mconv7_stage4_L1/biases/read/_128__cf__128\n",
            "TfPoseEstimator/Mconv7_stage4_L1/weights/read/_129__cf__129\n",
            "TfPoseEstimator/Mconv7_stage4_L2/biases/read/_130__cf__130\n",
            "TfPoseEstimator/Mconv7_stage4_L2/weights/read/_131__cf__131\n",
            "TfPoseEstimator/Mconv7_stage5_L1/biases/read/_132__cf__132\n",
            "TfPoseEstimator/Mconv7_stage5_L1/weights/read/_133__cf__133\n",
            "TfPoseEstimator/Mconv7_stage5_L2/biases/read/_134__cf__134\n",
            "TfPoseEstimator/Mconv7_stage5_L2/weights/read/_135__cf__135\n",
            "TfPoseEstimator/Mconv7_stage6_L1/biases/read/_136__cf__136\n",
            "TfPoseEstimator/Mconv7_stage6_L1/weights/read/_137__cf__137\n",
            "TfPoseEstimator/Mconv7_stage6_L2/biases/read/_138__cf__138\n",
            "TfPoseEstimator/Mconv7_stage6_L2/weights/read/_139__cf__139\n",
            "TfPoseEstimator/conv1_1/biases/read/_140__cf__140\n",
            "TfPoseEstimator/conv1_1/weights/read/_141__cf__141\n",
            "TfPoseEstimator/conv1_2/biases/read/_142__cf__142\n",
            "TfPoseEstimator/conv1_2/weights/read/_143__cf__143\n",
            "TfPoseEstimator/conv2_1/biases/read/_144__cf__144\n",
            "TfPoseEstimator/conv2_1/weights/read/_145__cf__145\n",
            "TfPoseEstimator/conv2_2/biases/read/_146__cf__146\n",
            "TfPoseEstimator/conv2_2/weights/read/_147__cf__147\n",
            "TfPoseEstimator/conv3_1/biases/read/_148__cf__148\n",
            "TfPoseEstimator/conv3_1/weights/read/_149__cf__149\n",
            "TfPoseEstimator/conv3_2/biases/read/_150__cf__150\n",
            "TfPoseEstimator/conv3_2/weights/read/_151__cf__151\n",
            "TfPoseEstimator/conv3_3/biases/read/_152__cf__152\n",
            "TfPoseEstimator/conv3_3/weights/read/_153__cf__153\n",
            "TfPoseEstimator/conv3_4/biases/read/_154__cf__154\n",
            "TfPoseEstimator/conv3_4/weights/read/_155__cf__155\n",
            "TfPoseEstimator/conv4_1/biases/read/_156__cf__156\n",
            "TfPoseEstimator/conv4_1/weights/read/_157__cf__157\n",
            "TfPoseEstimator/conv4_2/biases/read/_158__cf__158\n",
            "TfPoseEstimator/conv4_2/weights/read/_159__cf__159\n",
            "TfPoseEstimator/conv4_3_CPM/biases/read/_160__cf__160\n",
            "TfPoseEstimator/conv4_3_CPM/weights/read/_161__cf__161\n",
            "TfPoseEstimator/conv4_4_CPM/biases/read/_162__cf__162\n",
            "TfPoseEstimator/conv4_4_CPM/weights/read/_163__cf__163\n",
            "TfPoseEstimator/conv5_1_CPM_L1/biases/read/_164__cf__164\n",
            "TfPoseEstimator/conv5_1_CPM_L1/weights/read/_165__cf__165\n",
            "TfPoseEstimator/conv5_1_CPM_L2/biases/read/_166__cf__166\n",
            "TfPoseEstimator/conv5_1_CPM_L2/weights/read/_167__cf__167\n",
            "TfPoseEstimator/conv5_2_CPM_L1/biases/read/_168__cf__168\n",
            "TfPoseEstimator/conv5_2_CPM_L1/weights/read/_169__cf__169\n",
            "TfPoseEstimator/conv5_2_CPM_L2/biases/read/_170__cf__170\n",
            "TfPoseEstimator/conv5_2_CPM_L2/weights/read/_171__cf__171\n",
            "TfPoseEstimator/conv5_3_CPM_L1/biases/read/_172__cf__172\n",
            "TfPoseEstimator/conv5_3_CPM_L1/weights/read/_173__cf__173\n",
            "TfPoseEstimator/conv5_3_CPM_L2/biases/read/_174__cf__174\n",
            "TfPoseEstimator/conv5_3_CPM_L2/weights/read/_175__cf__175\n",
            "TfPoseEstimator/conv5_4_CPM_L1/biases/read/_176__cf__176\n",
            "TfPoseEstimator/conv5_4_CPM_L1/weights/read/_177__cf__177\n",
            "TfPoseEstimator/conv5_4_CPM_L2/biases/read/_178__cf__178\n",
            "TfPoseEstimator/conv5_4_CPM_L2/weights/read/_179__cf__179\n",
            "TfPoseEstimator/conv5_5_CPM_L1/biases/read/_180__cf__180\n",
            "TfPoseEstimator/conv5_5_CPM_L1/weights/read/_181__cf__181\n",
            "TfPoseEstimator/conv5_5_CPM_L2/biases/read/_182__cf__182\n",
            "TfPoseEstimator/conv5_5_CPM_L2/weights/read/_183__cf__183\n",
            "TfPoseEstimator/image\n",
            "TfPoseEstimator/preprocess_divide\n",
            "TfPoseEstimator/preprocess_subtract\n",
            "TfPoseEstimator/conv1_1/Conv2D\n",
            "TfPoseEstimator/conv1_1/BiasAdd\n",
            "TfPoseEstimator/conv1_1/conv1_1\n",
            "TfPoseEstimator/conv1_2/Conv2D\n",
            "TfPoseEstimator/conv1_2/BiasAdd\n",
            "TfPoseEstimator/conv1_2/conv1_2\n",
            "TfPoseEstimator/pool1_stage1\n",
            "TfPoseEstimator/conv2_1/Conv2D\n",
            "TfPoseEstimator/conv2_1/BiasAdd\n",
            "TfPoseEstimator/conv2_1/conv2_1\n",
            "TfPoseEstimator/conv2_2/Conv2D\n",
            "TfPoseEstimator/conv2_2/BiasAdd\n",
            "TfPoseEstimator/conv2_2/conv2_2\n",
            "TfPoseEstimator/pool2_stage1\n",
            "TfPoseEstimator/conv3_1/Conv2D\n",
            "TfPoseEstimator/conv3_1/BiasAdd\n",
            "TfPoseEstimator/conv3_1/conv3_1\n",
            "TfPoseEstimator/conv3_2/Conv2D\n",
            "TfPoseEstimator/conv3_2/BiasAdd\n",
            "TfPoseEstimator/conv3_2/conv3_2\n",
            "TfPoseEstimator/conv3_3/Conv2D\n",
            "TfPoseEstimator/conv3_3/BiasAdd\n",
            "TfPoseEstimator/conv3_3/conv3_3\n",
            "TfPoseEstimator/conv3_4/Conv2D\n",
            "TfPoseEstimator/conv3_4/BiasAdd\n",
            "TfPoseEstimator/conv3_4/conv3_4\n",
            "TfPoseEstimator/pool3_stage1\n",
            "TfPoseEstimator/conv4_1/Conv2D\n",
            "TfPoseEstimator/conv4_1/BiasAdd\n",
            "TfPoseEstimator/conv4_1/conv4_1\n",
            "TfPoseEstimator/conv4_2/Conv2D\n",
            "TfPoseEstimator/conv4_2/BiasAdd\n",
            "TfPoseEstimator/conv4_2/conv4_2\n",
            "TfPoseEstimator/conv4_3_CPM/Conv2D\n",
            "TfPoseEstimator/conv4_3_CPM/BiasAdd\n",
            "TfPoseEstimator/conv4_3_CPM/conv4_3_CPM\n",
            "TfPoseEstimator/conv4_4_CPM/Conv2D\n",
            "TfPoseEstimator/conv4_4_CPM/BiasAdd\n",
            "TfPoseEstimator/conv4_4_CPM/conv4_4_CPM\n",
            "TfPoseEstimator/conv5_1_CPM_L1/Conv2D\n",
            "TfPoseEstimator/conv5_1_CPM_L1/BiasAdd\n",
            "TfPoseEstimator/conv5_1_CPM_L1/conv5_1_CPM_L1\n",
            "TfPoseEstimator/conv5_2_CPM_L1/Conv2D\n",
            "TfPoseEstimator/conv5_2_CPM_L1/BiasAdd\n",
            "TfPoseEstimator/conv5_2_CPM_L1/conv5_2_CPM_L1\n",
            "TfPoseEstimator/conv5_3_CPM_L1/Conv2D\n",
            "TfPoseEstimator/conv5_3_CPM_L1/BiasAdd\n",
            "TfPoseEstimator/conv5_3_CPM_L1/conv5_3_CPM_L1\n",
            "TfPoseEstimator/conv5_4_CPM_L1/Conv2D\n",
            "TfPoseEstimator/conv5_4_CPM_L1/BiasAdd\n",
            "TfPoseEstimator/conv5_4_CPM_L1/conv5_4_CPM_L1\n",
            "TfPoseEstimator/conv5_5_CPM_L1/Conv2D\n",
            "TfPoseEstimator/conv5_5_CPM_L1/BiasAdd\n",
            "TfPoseEstimator/conv5_1_CPM_L2/Conv2D\n",
            "TfPoseEstimator/conv5_1_CPM_L2/BiasAdd\n",
            "TfPoseEstimator/conv5_1_CPM_L2/conv5_1_CPM_L2\n",
            "TfPoseEstimator/conv5_2_CPM_L2/Conv2D\n",
            "TfPoseEstimator/conv5_2_CPM_L2/BiasAdd\n",
            "TfPoseEstimator/conv5_2_CPM_L2/conv5_2_CPM_L2\n",
            "TfPoseEstimator/conv5_3_CPM_L2/Conv2D\n",
            "TfPoseEstimator/conv5_3_CPM_L2/BiasAdd\n",
            "TfPoseEstimator/conv5_3_CPM_L2/conv5_3_CPM_L2\n",
            "TfPoseEstimator/conv5_4_CPM_L2/Conv2D\n",
            "TfPoseEstimator/conv5_4_CPM_L2/BiasAdd\n",
            "TfPoseEstimator/conv5_4_CPM_L2/conv5_4_CPM_L2\n",
            "TfPoseEstimator/conv5_5_CPM_L2/Conv2D\n",
            "TfPoseEstimator/conv5_5_CPM_L2/BiasAdd\n",
            "TfPoseEstimator/concat_stage2\n",
            "TfPoseEstimator/Mconv1_stage2_L1/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage2_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage2_L1/Mconv1_stage2_L1\n",
            "TfPoseEstimator/Mconv2_stage2_L1/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage2_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage2_L1/Mconv2_stage2_L1\n",
            "TfPoseEstimator/Mconv3_stage2_L1/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage2_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage2_L1/Mconv3_stage2_L1\n",
            "TfPoseEstimator/Mconv4_stage2_L1/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage2_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage2_L1/Mconv4_stage2_L1\n",
            "TfPoseEstimator/Mconv5_stage2_L1/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage2_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage2_L1/Mconv5_stage2_L1\n",
            "TfPoseEstimator/Mconv6_stage2_L1/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage2_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage2_L1/Mconv6_stage2_L1\n",
            "TfPoseEstimator/Mconv7_stage2_L1/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage2_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage2_L2/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage2_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage2_L2/Mconv1_stage2_L2\n",
            "TfPoseEstimator/Mconv2_stage2_L2/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage2_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage2_L2/Mconv2_stage2_L2\n",
            "TfPoseEstimator/Mconv3_stage2_L2/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage2_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage2_L2/Mconv3_stage2_L2\n",
            "TfPoseEstimator/Mconv4_stage2_L2/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage2_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage2_L2/Mconv4_stage2_L2\n",
            "TfPoseEstimator/Mconv5_stage2_L2/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage2_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage2_L2/Mconv5_stage2_L2\n",
            "TfPoseEstimator/Mconv6_stage2_L2/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage2_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage2_L2/Mconv6_stage2_L2\n",
            "TfPoseEstimator/Mconv7_stage2_L2/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage2_L2/BiasAdd\n",
            "TfPoseEstimator/concat_stage3\n",
            "TfPoseEstimator/Mconv1_stage3_L1/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage3_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage3_L1/Mconv1_stage3_L1\n",
            "TfPoseEstimator/Mconv2_stage3_L1/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage3_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage3_L1/Mconv2_stage3_L1\n",
            "TfPoseEstimator/Mconv3_stage3_L1/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage3_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage3_L1/Mconv3_stage3_L1\n",
            "TfPoseEstimator/Mconv4_stage3_L1/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage3_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage3_L1/Mconv4_stage3_L1\n",
            "TfPoseEstimator/Mconv5_stage3_L1/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage3_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage3_L1/Mconv5_stage3_L1\n",
            "TfPoseEstimator/Mconv6_stage3_L1/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage3_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage3_L1/Mconv6_stage3_L1\n",
            "TfPoseEstimator/Mconv7_stage3_L1/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage3_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage3_L2/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage3_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage3_L2/Mconv1_stage3_L2\n",
            "TfPoseEstimator/Mconv2_stage3_L2/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage3_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage3_L2/Mconv2_stage3_L2\n",
            "TfPoseEstimator/Mconv3_stage3_L2/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage3_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage3_L2/Mconv3_stage3_L2\n",
            "TfPoseEstimator/Mconv4_stage3_L2/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage3_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage3_L2/Mconv4_stage3_L2\n",
            "TfPoseEstimator/Mconv5_stage3_L2/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage3_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage3_L2/Mconv5_stage3_L2\n",
            "TfPoseEstimator/Mconv6_stage3_L2/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage3_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage3_L2/Mconv6_stage3_L2\n",
            "TfPoseEstimator/Mconv7_stage3_L2/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage3_L2/BiasAdd\n",
            "TfPoseEstimator/concat_stage4\n",
            "TfPoseEstimator/Mconv1_stage4_L1/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage4_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage4_L1/Mconv1_stage4_L1\n",
            "TfPoseEstimator/Mconv2_stage4_L1/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage4_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage4_L1/Mconv2_stage4_L1\n",
            "TfPoseEstimator/Mconv3_stage4_L1/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage4_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage4_L1/Mconv3_stage4_L1\n",
            "TfPoseEstimator/Mconv4_stage4_L1/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage4_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage4_L1/Mconv4_stage4_L1\n",
            "TfPoseEstimator/Mconv5_stage4_L1/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage4_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage4_L1/Mconv5_stage4_L1\n",
            "TfPoseEstimator/Mconv6_stage4_L1/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage4_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage4_L1/Mconv6_stage4_L1\n",
            "TfPoseEstimator/Mconv7_stage4_L1/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage4_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage4_L2/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage4_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage4_L2/Mconv1_stage4_L2\n",
            "TfPoseEstimator/Mconv2_stage4_L2/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage4_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage4_L2/Mconv2_stage4_L2\n",
            "TfPoseEstimator/Mconv3_stage4_L2/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage4_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage4_L2/Mconv3_stage4_L2\n",
            "TfPoseEstimator/Mconv4_stage4_L2/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage4_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage4_L2/Mconv4_stage4_L2\n",
            "TfPoseEstimator/Mconv5_stage4_L2/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage4_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage4_L2/Mconv5_stage4_L2\n",
            "TfPoseEstimator/Mconv6_stage4_L2/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage4_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage4_L2/Mconv6_stage4_L2\n",
            "TfPoseEstimator/Mconv7_stage4_L2/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage4_L2/BiasAdd\n",
            "TfPoseEstimator/concat_stage5\n",
            "TfPoseEstimator/Mconv1_stage5_L1/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage5_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage5_L1/Mconv1_stage5_L1\n",
            "TfPoseEstimator/Mconv2_stage5_L1/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage5_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage5_L1/Mconv2_stage5_L1\n",
            "TfPoseEstimator/Mconv3_stage5_L1/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage5_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage5_L1/Mconv3_stage5_L1\n",
            "TfPoseEstimator/Mconv4_stage5_L1/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage5_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage5_L1/Mconv4_stage5_L1\n",
            "TfPoseEstimator/Mconv5_stage5_L1/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage5_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage5_L1/Mconv5_stage5_L1\n",
            "TfPoseEstimator/Mconv6_stage5_L1/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage5_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage5_L1/Mconv6_stage5_L1\n",
            "TfPoseEstimator/Mconv7_stage5_L1/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage5_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage5_L2/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage5_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage5_L2/Mconv1_stage5_L2\n",
            "TfPoseEstimator/Mconv2_stage5_L2/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage5_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage5_L2/Mconv2_stage5_L2\n",
            "TfPoseEstimator/Mconv3_stage5_L2/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage5_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage5_L2/Mconv3_stage5_L2\n",
            "TfPoseEstimator/Mconv4_stage5_L2/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage5_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage5_L2/Mconv4_stage5_L2\n",
            "TfPoseEstimator/Mconv5_stage5_L2/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage5_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage5_L2/Mconv5_stage5_L2\n",
            "TfPoseEstimator/Mconv6_stage5_L2/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage5_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage5_L2/Mconv6_stage5_L2\n",
            "TfPoseEstimator/Mconv7_stage5_L2/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage5_L2/BiasAdd\n",
            "TfPoseEstimator/concat_stage6\n",
            "TfPoseEstimator/Mconv1_stage6_L1/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage6_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage6_L1/Mconv1_stage6_L1\n",
            "TfPoseEstimator/Mconv2_stage6_L1/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage6_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage6_L1/Mconv2_stage6_L1\n",
            "TfPoseEstimator/Mconv3_stage6_L1/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage6_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage6_L1/Mconv3_stage6_L1\n",
            "TfPoseEstimator/Mconv4_stage6_L1/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage6_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage6_L1/Mconv4_stage6_L1\n",
            "TfPoseEstimator/Mconv5_stage6_L1/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage6_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage6_L1/Mconv5_stage6_L1\n",
            "TfPoseEstimator/Mconv6_stage6_L1/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage6_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage6_L1/Mconv6_stage6_L1\n",
            "TfPoseEstimator/Mconv7_stage6_L1/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage6_L1/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage6_L2/Conv2D\n",
            "TfPoseEstimator/Mconv1_stage6_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv1_stage6_L2/Mconv1_stage6_L2\n",
            "TfPoseEstimator/Mconv2_stage6_L2/Conv2D\n",
            "TfPoseEstimator/Mconv2_stage6_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv2_stage6_L2/Mconv2_stage6_L2\n",
            "TfPoseEstimator/Mconv3_stage6_L2/Conv2D\n",
            "TfPoseEstimator/Mconv3_stage6_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv3_stage6_L2/Mconv3_stage6_L2\n",
            "TfPoseEstimator/Mconv4_stage6_L2/Conv2D\n",
            "TfPoseEstimator/Mconv4_stage6_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv4_stage6_L2/Mconv4_stage6_L2\n",
            "TfPoseEstimator/Mconv5_stage6_L2/Conv2D\n",
            "TfPoseEstimator/Mconv5_stage6_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv5_stage6_L2/Mconv5_stage6_L2\n",
            "TfPoseEstimator/Mconv6_stage6_L2/Conv2D\n",
            "TfPoseEstimator/Mconv6_stage6_L2/BiasAdd\n",
            "TfPoseEstimator/Mconv6_stage6_L2/Mconv6_stage6_L2\n",
            "TfPoseEstimator/Mconv7_stage6_L2/Conv2D\n",
            "TfPoseEstimator/Mconv7_stage6_L2/BiasAdd\n",
            "TfPoseEstimator/Openpose/concat_stage7\n",
            "HEEEEJ\n",
            "Tensor(\"strided_slice_2:0\", shape=(?, ?, ?, 19), dtype=float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0504 06:52:06.396773 140519420950336 deprecation.py:641] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:576: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`normal` is a deprecated alias for `truncated_normal`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Volvo-DataX\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0504 06:52:06.564311 140519420950336 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zZrlYUP1Qkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866f8ac8-eb51-4fd2-beb0-c565b7ff5de0"
      },
      "source": [
        "\n",
        "\n",
        "FLAGS.yolo_iou_threshold = 0.5\n",
        "FLAGS.yolo_score_threshold = 0.5\n",
        "\n",
        "color = (255, 0, 0)\n",
        "thickness = 2\n",
        "\n",
        "yolo = YoloV3(classes=FLAGS.num_classes)\n",
        "\n",
        "yolo.load_weights(FLAGS.weights).expect_partial()\n",
        "logging.info('weights loaded')\n",
        "\n",
        "class_names = [c.strip() for c in open(FLAGS.classes).readlines()]\n",
        "logging.info('classes loaded')\n",
        "\n",
        "resize_out_ratio = 4.0\n",
        "\n",
        "def run_model():\n",
        "\n",
        "  print('Processing started.......')\n",
        "\n",
        "  fps_time = 0\n",
        "\n",
        "  try:\n",
        "      vid = cv2.VideoCapture(int(FLAGS.video))\n",
        "  except:\n",
        "      vid = cv2.VideoCapture(FLAGS.video)\n",
        "\n",
        "  out = None\n",
        "\n",
        "  if FLAGS.output:\n",
        "      # by default VideoCapture returns float instead of int\n",
        "      width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "      height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "      fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "      codec = cv2.VideoWriter_fourcc(*FLAGS.output_format)\n",
        "      out = cv2.VideoWriter(FLAGS.output, codec, fps, (width, height))\n",
        "\n",
        "  frame = 0\n",
        "  rolling_data={}\n",
        "  fps_time=0\n",
        "\n",
        "  while True:\n",
        "\n",
        "    _, img = vid.read() # reading the image\n",
        "\n",
        "    if img is None:\n",
        "        break\n",
        "        logging.warning(\"Empty Frame\")\n",
        "        time.sleep(0.1)\n",
        "        continue\n",
        "    frame += 1\n",
        "    currFrame = int(vid.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "    fps = vid.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "\n",
        "    img_in = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_orig = np.copy(img)\n",
        "    img_in = tf.expand_dims(img_in, 0)\n",
        "    img_in = transform_images(img_in, FLAGS.size)\n",
        "\n",
        "    t1 = time.time()\n",
        "    boxes, scores, classes, nums = yolo.predict(img_in, steps=1) # yolo\n",
        "    t2 = time.time()\n",
        "\n",
        "    # for 80 cls yolo\n",
        "\n",
        "    boxes = boxes[:,:nums[0],:].reshape(nums[0], 4)[classes[0][:nums[0]] == 0]\n",
        "    scores = scores[0][:nums[0]][classes[0][:nums[0]] == 0]\n",
        "    nums = len(boxes)\n",
        "\n",
        "    wh = np.flip(img.shape[0:2])\n",
        "    bbtlwh = []\n",
        "    for i in range(nums):\n",
        "\n",
        "\n",
        "      x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
        "      x1 = x1y1[0]\n",
        "      y1 = x1y1[1]\n",
        "      x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
        "      bbwh = (x2y2[0]-x1y1[0], x2y2[1]-x1y1[1])\n",
        "      w = bbwh[0]\n",
        "      h = bbwh[1]\n",
        "      bbtlwh.append([x1,y1,w,h])\n",
        "\n",
        "    features = encoder(img, bbtlwh) # deepsort input\n",
        "    detections = [Detection(box, conf, feat) for box, conf, feat in zip(bbtlwh, scores, features)] #deep sort output\n",
        "\n",
        "    # Update tracker.\n",
        "    tracker.predict()\n",
        "    tracker.update(detections)\n",
        "\n",
        "    tracked_bbox = []\n",
        "    ids = []\n",
        "\n",
        "    for track in tracker.tracks:\n",
        "\n",
        "      if not track.is_confirmed() or track.time_since_update > 1:\n",
        "        continue\n",
        "      tracked_bbox.append(track.to_tlwh())\n",
        "      ids.append(track.track_id)\n",
        "\n",
        "\n",
        "    for i in range(len(tracked_bbox)): # densenet\n",
        "\n",
        "      # Show tracker output\n",
        "      x, y, w, h = tracked_bbox[i]\n",
        "      x = int(x)\n",
        "      y = int(y)\n",
        "      w = int(w)\n",
        "      h = int(h)\n",
        "\n",
        "      # plot the skeletons\n",
        "      try:\n",
        "        cropped = img_orig[y:y + h, x:x + w]\n",
        "        humans = model.inference(cropped, resize_to_default=(w > 0 and h > 0), upsample_size=resize_out_ratio)\n",
        "        humans.sort(key=lambda human: human.score, reverse=True)\n",
        "        skelett = TfPoseEstimator.draw_humans(cropped, humans, imgcopy=True)\n",
        "        img_orig[y:y + h, x:x + w] = skelett\n",
        "        img_orig2 = img_orig\n",
        "\n",
        "      except:\n",
        "        img_orig2 = img_orig\n",
        "\n",
        "      # looking for previous 16 frames data for a given pedestrian:\n",
        "\n",
        "      intent = 0 #(default, the pedestrian is not crossing)\n",
        "\n",
        "\n",
        "      if int(ids[i]) in list(rolling_data.keys()):\n",
        "\n",
        "        if len(rolling_data[int(ids[i])]) == 16:\n",
        "\n",
        "          seq = np.stack(np.array(rolling_data[int(ids[i])]),axis=2)\n",
        "          seq = np.expand_dims(seq, axis=0)\n",
        "          intent = pred_func(seq) # classification output\n",
        "\n",
        "        else:\n",
        "\n",
        "          seq = np.stack(np.array([rolling_data[int(ids[i])][-1]] * 16),axis=2)\n",
        "          seq = np.expand_dims(seq, axis=0)\n",
        "          intent = pred_func(seq) # classification output\n",
        "\n",
        "\n",
        "      # risky pedestrian identification thru box color\n",
        "\n",
        "      if intent == 1:\n",
        "        color = (0, 0, 255) # Red -> Crossing\n",
        "\n",
        "      else:\n",
        "        color = (0, 255, 0) # green -> Not crossing\n",
        "\n",
        "      fps_time = time.time()\n",
        "      img = cv2.rectangle(img_orig2, (int(x), int(y)), (int(x + w), int(y + h)), color, 2)\n",
        "      img = cv2.putText(img, 'TrackID ' + str(ids[i]), (x, y - 5), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(255, 0, 0), thickness=2)\n",
        "      img = cv2.putText(img,\"Frame No: %d\" % (frame),(10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0, 0, 255), 2)\n",
        "\n",
        "      # storing the data for last 16 frames\n",
        "# this is a test comment for running the command to shoot a video and thus this much typing\n",
        "# now lest move to the second line which is again a timepass to shoot a video\n",
        "#now the third line which is again a timepass to work and have fun while shooting no other reson to type this much\n",
        "#why type when you can speak and why speak when you type\n",
        "      try:\n",
        "\n",
        "        if int(ids[i]) in list(rolling_data.keys()): # ID exists in dict\n",
        "\n",
        "          if len(rolling_data[int(ids[i])]) < 16: # bboxes values for 16 frames\n",
        "\n",
        "            cropped_seq = []\n",
        "            cropped_img = cv2.resize(img_orig[y:h+y, x:w+x],(100,100))\n",
        "            rolling_data[int(ids[i])].append(np.asarray(cropped_img)) # append the image\n",
        "\n",
        "          else:\n",
        "\n",
        "            del rolling_data[int(ids[i])][0] # delete oldest frame bbox and append latest frame bbox\n",
        "            cropped_seq = []\n",
        "            cropped_img = cv2.resize(img_orig[y:h+y, x:w+x],(100,100))\n",
        "            rolling_data[int(ids[i])].append(np.asarray(cropped_img))\n",
        "\n",
        "        else:\n",
        "\n",
        "          cropped_seq = []\n",
        "          cropped_img = cv2.resize(img_orig[y:h+y, x:w+x],(100,100))\n",
        "          rolling_data[int(ids[i])] = [np.asarray(cropped_img)]\n",
        "\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "\n",
        "    if FLAGS.output:\n",
        "      out.write(img)\n",
        "\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "      break\n",
        "\n",
        "  cv2.destroyAllWindows()\n",
        "  print('\\nProcessing completed.......!!!')\n",
        "  print('Check video file in Volvo-DataX folder!')\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "I0504 06:52:38.480125 140519420950336 <ipython-input-3-fdd16c3f0b95>:11] weights loaded\n",
            "I0504 06:52:38.483900 140519420950336 <ipython-input-3-fdd16c3f0b95>:14] classes loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw1oCBxzWpPU"
      },
      "source": [
        "\n",
        "###6. Run this to obtain the output as a video file\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDixMreeUS_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e114d7c8-0636-4588-ba74-df6c79f3a191"
      },
      "source": [
        "run_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing started.......\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/content/utils/linear_assignment_.py:124: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn0ghtMvT98N"
      },
      "source": [
        "To download the result video generated, search for it inside the Volvo-DataX folder in the left pane of the colab notebook and download the file from there."
      ]
    }
  ]
}